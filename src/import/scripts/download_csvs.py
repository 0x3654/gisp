import hashlib
import os
import sys
from datetime import datetime, timedelta
from typing import Optional, Tuple

import requests

BASE_URL = (
    "https://minpromtorg.gov.ru/opendata/"
    "1000000012-ReestrProducts/data-{date}-structure-20210405.csv"
)
FILES_DIR = os.getenv("FILES_DIR") or "/files"
START_DATE = datetime(2024, 9, 5)
END_DATE = datetime.today()
USER_AGENT = (
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/116.0.0.0 Safari/537.36"
)


def ensure_files_dir() -> None:
    if not FILES_DIR:
        print("‚ùå –ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è FILES_DIR –Ω–µ –∑–∞–¥–∞–Ω–∞.", file=sys.stderr)
        sys.exit(1)
    os.makedirs(FILES_DIR, exist_ok=True)


def existing_latest_date() -> Optional[datetime]:
    dates = []
    for fname in os.listdir(FILES_DIR or ""):
        if not fname.startswith("data-") or not fname.endswith(".csv"):
            continue
        try:
            date_str = fname.split("-")[1]
            dates.append(datetime.strptime(date_str, "%Y%m%d"))
        except Exception:
            continue
    return max(dates) if dates else None


def compose_filename(dt: datetime) -> Tuple[str, str]:
    date_str = dt.strftime("%Y%m%d")
    name = f"data-{date_str}-structure-20210405.csv"
    path = os.path.join(FILES_DIR, name)
    return name, path


def try_fetch(date_candidate: datetime) -> Optional[bytes]:
    url = BASE_URL.format(date=date_candidate.strftime("%Y%m%d"))
    headers = {"User-Agent": USER_AGENT}

    # Retry logic with exponential backoff
    max_retries = 3
    quick_timeout = 10  # Quick timeout for first attempt (file either exists or 404 fast)
    base_timeout = 60   # Longer timeout for retries (network issues)

    for attempt in range(max_retries):
        try:
            # First attempt: quick timeout, retries: longer timeout for slow downloads
            timeout = quick_timeout if attempt == 0 else base_timeout * (2 ** (attempt - 1))
            print(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}/{max_retries} –¥–ª—è {date_candidate:%d.%m.%Y} (timeout={timeout}s)...", flush=True)
            response = requests.get(url, headers=headers, timeout=timeout)

            if response.status_code == 404:
                return None
            response.raise_for_status()

            if not response.content:
                raise RuntimeError("–ü–æ–ª—É—á–µ–Ω –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞")

            print(f"‚úÖ –£—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω–æ –∑–∞ {attempt + 1} –ø–æ–ø—ã—Ç–∫–∏", flush=True)
            return response.content

        except requests.HTTPError as http_err:
            if attempt == max_retries - 1:
                print(f"‚ö†Ô∏è  HTTP –æ—à–∏–±–∫–∞ {http_err.response.status_code} –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}", flush=True)
            if attempt < max_retries - 1:
                wait_time = 5 * (2 ** attempt)  # Exponential backoff: 5s, 10s, 20s
                print(f"‚è≥ –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —á–µ—Ä–µ–∑ {wait_time} —Å–µ–∫...", flush=True)
                import time
                time.sleep(wait_time)
            else:
                raise

        except requests.RequestException as req_err:
            if attempt < max_retries - 1:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {req_err}", flush=True)
            if attempt == max_retries - 1:
                raise
            # Continue retry loop

    return None  # All retries exhausted


def compute_sha256(data: bytes) -> str:
    return hashlib.sha256(data).hexdigest()


def file_sha256(path: str) -> Optional[str]:
    if not os.path.exists(path):
        return None
    sha = hashlib.sha256()
    with open(path, "rb") as fh:
        for chunk in iter(lambda: fh.read(1024 * 1024), b""):
            sha.update(chunk)
    return sha.hexdigest()


def _next_required_date(last_existing: Optional[datetime]) -> datetime:
    if last_existing:
        return max(START_DATE, last_existing + timedelta(days=1))
    return START_DATE


def find_latest_payload(last_existing: Optional[datetime]) -> Optional[Tuple[datetime, bytes]]:
    current = END_DATE
    earliest_required = _next_required_date(last_existing)
    last_known_str = last_existing.strftime("%d.%m.%Y") if last_existing else "–Ω–µ—Ç —Ñ–∞–π–ª–æ–≤"
    if earliest_required > current:
        print("‚ÑπÔ∏è  –ù–æ–≤—ã—Ö –¥–∞—Ç –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –Ω–µ—Ç: –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª —Å–≤–µ–∂–∏–π.", file=sys.stderr)
        return None

    attempts = 0

    while current >= earliest_required:
        attempts += 1
        name, path = compose_filename(current)

        if os.path.exists(path):
            print(f"‚úÖ  –£–∂–µ —Å–∫–∞—á–∞–Ω: {name}, –¥–∞–ª—å—à–µ –∏—Å–∫–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ.")
            return None

        payload = try_fetch(current)
        if payload:
            return current, payload

        # If fetch failed (returned None), move to previous day
        print(f"‚ÑπÔ∏è  –î–∞—Ç–∞ {current:%d.%m.%Y} –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∞, –ø—Ä–æ–±—É–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π –¥–µ–Ω—å...", flush=True)
        current -= timedelta(days=1)

    print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –Ω–æ–≤—ã–µ CSV.", file=sys.stderr)
    print(f"–î–∞—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Ñ–∞–π–ª–∞: {last_known_str}", file=sys.stderr)
    print(f"–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {END_DATE:%d.%m.%Y}", file=sys.stderr)
    if attempts > 0:
        print(
            f"–î–∏–∞–ø–∞–∑–æ–Ω –ø–æ–∏—Å–∫–∞: {earliest_required:%d.%m.%Y} ‚Äî {END_DATE:%d.%m.%Y}, –ø–æ–ø—ã—Ç–æ–∫: {attempts}",
            file=sys.stderr,
        )
    return None


def save_payload(path: str, data: bytes) -> None:
    tmp_path = f"{path}.tmp"
    with open(tmp_path, "wb") as fh:
        fh.write(data)
    os.replace(tmp_path, path)


def download_latest() -> None:
    ensure_files_dir()
    last_existing = existing_latest_date()
    if last_existing and last_existing > END_DATE:
        last_existing = END_DATE

    if last_existing:
        print(f"‚ÑπÔ∏è  –ü–æ—Å–ª–µ–¥–Ω–∏–π —Ñ–∞–π–ª –≤ –ø–∞–ø–∫–µ: {last_existing:%d.%m.%Y}")
    else:
        print("‚ÑπÔ∏è  CSV –≤ –ø–∞–ø–∫–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")

    result = find_latest_payload(last_existing)
    if not result:
        return

    remote_date, payload = result
    name, path = compose_filename(remote_date)
    remote_sha = compute_sha256(payload)

    local_sha = file_sha256(path)
    if local_sha == remote_sha:
        print(f"‚úÖ  –ê–∫—Ç—É–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —É–∂–µ —Å–∫–∞—á–∞–Ω: {name}")
        return

    save_payload(path, payload)
    size_mb = len(payload) / (1024 * 1024)

    print(f"üíæ  –°–∫–∞—á–∞–Ω —Ñ–∞–π–ª {name} ({size_mb:.2f} MB)")
    print(f"üïí  –î–∞—Ç–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {remote_date:%d.%m.%Y}")


if __name__ == "__main__":
    mode = sys.argv[1] if len(sys.argv) > 1 else "latest"
    if mode not in {"latest", "new", "all"}:
        print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python download_csvs.py [latest]", file=sys.stderr)
        sys.exit(1)

    if mode in {"new", "all"}:
        print("‚ÑπÔ∏è  –†–µ–∂–∏–º—ã 'new' –∏ 'all' —É—Å—Ç–∞—Ä–µ–ª–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º 'latest'.")

    download_latest()
